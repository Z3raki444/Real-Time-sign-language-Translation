ğŸ§¾ Real-Time Sign Language Translation (ASL)

This project implements a real-time American Sign Language (ASL) alphabet recognition system using a webcam and a custom-trained deep learning model. It provides a simple, beginner-friendly approach to gesture translation without relying on MediaPipe or contour-based tracking.

The system uses OpenCV for video capture and PyTorch for classification. A Convolutional Neural Network (CNN) is trained on hand images representing the ASL alphabet, and the trained model performs real-time prediction on a live video feed. The design is modular, making it easy to extend to more gestures, dynamic signs, or full-word recognition.

ğŸš€ Features

ğŸ¥ Real-time sign detection from webcam

ğŸ¤– Custom PyTorch CNN model

âœ‹ Recognizes ASL alphabet (Aâ€“Z)

ğŸ“¦ Clean and modular pipeline

ğŸ“ No MediaPipe, no contours

ğŸ§© Easily extendable for advanced gesture recognition
